--- 
title: "Thesis"
author: "Peter Hrvola phrv@itu.dk"
date: "`r Sys.Date()`"
site: bookdown::bookdown_site
output:
  bookdown::pdf_document2:
    toc: false
documentclass: article
bibliography: [book.bib]
biblio-style: alpha
link-citations: yes
github-repo: rstudio/bookdown-demo
description: "FIXME"
geometry: "left=2.5cm, right=2.5cm, top=2.5cm, bottom=2.5cm"
classoption: twoside
---
# Profiles

## Workloads

### Factor

Rather boring, application is utilizing all cores to 100% but IPC is still quite low when compared to other
```{r echo=FALSE, message=FALSE}
library(plotly)
library(gapminder)

source("process.R")

data1 <- read_processed("measurements/factor.csv");

cpu <- read_processed("measurements/memory.csv");
disk <- read_processed("measurements/disk.csv");
memory <- read_processed("measurements/memory.csv");
network <- read_processed("measurements/network.csv");

max_profile <- local(prof(list(cpu, disk, memory, network, data1)))

show_graph(data1, max_profile)

```

### Echoserver

The measurement starts before the requests are sent from the client. First request are received when we see the jump in the network. I send 16*1 GB files every 1s for 100 times. Files are memory mapped by mountig ramfs (required sudo) from dionysos, would be nice if I could send them from the other server in DMZ, I think using HPC for this could be too complicated and currently I need sudo to mount ramfs. CPU is utilized to maximum as reported by htop but spending 90% in kernel most probably interrupts and networking.

```{r echo=FALSE, message=FALSE}
library(plotly)
library(gapminder)

source("process.R")

data1 <- read_processed("measurements/echo.csv");

cpu <- read_processed("measurements/memory.csv");
disk <- read_processed("measurements/disk.csv");
memory <- read_processed("measurements/memory.csv");
network <- read_processed("measurements/network.csv");

max_profile <- local(prof(list(cpu, disk, memory, network, data1)))

show_graph(data1, max_profile)

```

### Hadoop 

I took two samples for Hadoop, I would say they are similar and showing almost the same profile

#### Hadoop first measurement
```{r echo=FALSE, message=FALSE}
library(plotly)
library(gapminder)

source("process.R")

data1 <- read_processed("measurements/hadoop-1.csv");

cpu <- read_processed("measurements/memory.csv");
disk <- read_processed("measurements/disk.csv");
memory <- read_processed("measurements/memory.csv");
network <- read_processed("measurements/network.csv");

max_profile <- local(prof(list(cpu, disk, memory, network, data1)))

show_graph(data1, max_profile)

```

#### Hadoop seconds measurement
```{r echo=FALSE, message=FALSE}
library(plotly)
library(gapminder)

source("process.R")

data1 <- read_processed("measurements/hadoop-2.csv");

cpu <- read_processed("measurements/memory.csv");
disk <- read_processed("measurements/disk.csv");
memory <- read_processed("measurements/memory.csv");
network <- read_processed("measurements/network.csv");

max_profile <- local(prof(list(cpu, disk, memory, network, data1)))

show_graph(data1, max_profile)

```

## Benchmarks

### CPU

It's essentially Factor app with different set of numbers
```{r echo=FALSE, message=FALSE}
library(plotly)
library(gapminder)

source("process.R")

data1 <- read_processed("measurements/cpu.csv");

cpu <- read_processed("measurements/memory.csv");
disk <- read_processed("measurements/disk.csv");
memory <- read_processed("measurements/memory.csv");
network <- read_processed("measurements/network.csv");

max_profile <- local(prof(list(cpu, disk, memory, network, data1)))

show_graph(data1, max_profile)

```

### Disk

Creating random data in memory and writing to 5 files at the same time
```{r echo=FALSE, message=FALSE}
library(plotly)
library(gapminder)

source("process.R")

data1 <- read_processed("measurements/disk.csv");

cpu <- read_processed("measurements/memory.csv");
disk <- read_processed("measurements/disk.csv");
memory <- read_processed("measurements/memory.csv");
network <- read_processed("measurements/network.csv");

max_profile <- local(prof(list(cpu, disk, memory, network, data1)))

show_graph(data1, max_profile)

```

### Memory

Allocating memory with random data and computing it's hash (to prevent optimizer from removing the call)
```{r echo=FALSE, message=FALSE}
library(plotly)
library(gapminder)

source("process.R")

data1 <- read_processed("measurements/memory.csv");

cpu <- read_processed("measurements/memory.csv");
disk <- read_processed("measurements/disk.csv");
memory <- read_processed("measurements/memory.csv");
network <- read_processed("measurements/network.csv");

max_profile <- local(prof(list(cpu, disk, memory, network, data1)))

show_graph(data1, max_profile)

```

### Network

Download 1gb of data full speed
```{r echo=FALSE, message=FALSE}
library(plotly)
library(gapminder)

source("process.R")

data1 <- read_processed("measurements/network.csv");

cpu <- read_processed("measurements/memory.csv");
disk <- read_processed("measurements/disk.csv");
memory <- read_processed("measurements/memory.csv");
network <- read_processed("measurements/network.csv");

max_profile <- local(prof(list(cpu, disk, memory, network, data1)))

show_graph(data1, max_profile)

```
